{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e5592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d90a2e",
   "metadata": {},
   "source": [
    "# Project 1: Data analysis\n",
    "\n",
    "## Bayesian approch\n",
    "\n",
    "In order to predict the effect of genes on symptoms, we will use a simple Bayesian model. We consider these hypothesis:\n",
    "\n",
    "$$\\mu_0: P(symptoms|genes) = P(symptoms)$$\n",
    "$$\\mu_1: P(symptoms|genes) \\neq P(symptoms)$$\n",
    "\n",
    "In order words, does the genes have any effect on the symptoms or not? If it does, which genomes are the most relevant for the preventing the symptoms? \n",
    "\n",
    "We let Y be the symptoms and our X the genes. Y is an 8 bit vector for each observation, with 1 or zero for each bit. X is an 128 with the same charectaristic as Y.\n",
    "\n",
    "The probability distribution of $ Y $ depends on an unknown parameter that we assume to be stochastic. We call this unknown parameter $\\theta$, or in our program, $ p $. \n",
    "\n",
    "The formulation under is an alternative formulation of the the previous hypotesis. Does the parameter that the probability distribution of Y depend on, depend on X or not. $ \\mu_0 $, our null, says that it does not. $\\mu_1 $, the alternative hypothesis claims it does. We assume the Beta-Bernoulli model:\n",
    " \n",
    "$$\\mu_0: \\theta_0 \\sim Beta(\\alpha_0 , \\beta_0) ,  \\ \\ \\  Y | \\theta_0  $$\n",
    "$$\\mu_1: \\theta_{1,x_t} \\sim Beta(\\alpha_{1,x_t} , \\beta_{1,x_t}) , \\ \\ \\ y_t | x_t \\sim bernoulli(\\theta_{1,x_t}) $$\n",
    " \n",
    "\n",
    "Given the data, D, we try to estimate\n",
    "\n",
    "$$ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_1}(D) \\cdot \\xi(\\mu_1)} $$\n",
    "\n",
    "For simplicity, let $\\mu = \\mu_0$ or $\\mu = \\mu_1$. We define the posterior belief:\n",
    "\n",
    "Let $P_{\\mu} (D) = P(\\mu |D)$ for $D = (x_t, y_t,x_{t-1},y_{t-1})_{t=1} ^T $ for a spesific gene X, and let $x_t$ be the value (0  or 1) of the gene for one observation, t, then $x_{t-1}$ is a vector of all the values for the previous observations including t-1. Further, let $y_t$ be the the value (0 or 1) of symptom Y for observation t defined in the same way. We assume that the different observations are independent. That is, \n",
    "\n",
    "$$ \\begin{align*}P_{\\mu}(D) & = P(y_1,...,y_t \\cup x_1,...,x_t) \\\\ \n",
    "              & = \\prod_{i=1}^{t} P(y_i | x_i,x_{i-1} , y_{i-1}) \\end{align*} $$\n",
    "\n",
    "With these assumptions, we can estimate $P_{\\mu} (D)$: \n",
    "$$ P(y_t | x_t,x_{t-1} , y_{t-1}) = \\int_{\\theta} P_{\\theta}(y_t|x_t) \\cdot \\xi(\\theta|x_{t-1},y_{t-1})$$\n",
    "\n",
    "This makes adding new observations and updating beliefs easy. It works if we assume that a new observation is independent of the previous.\n",
    "\n",
    "This estimate is called the marginal likelihood (posterior predictive distribution). It is a compound distribution. The probabilty $P(y_t | x_{t})$ is stochastic in $\\theta$, so we have to integrate over all values of $\\theta$. Every time a new observation is added we compute $$P(y_t | x_{t},x_{t-1}, y_{t-1})$$, and recalculate $$ \\prod_{i=1}^{t} P(y_i | x_i ,x_{i-1}, y_{i-1}) $$. \n",
    "\n",
    "When calculating $$ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_i}(D) \\cdot \\xi(\\mu_i)} $$ we are sequentially updating our belief every time a new observation is added. For every update $\\xi(\\mu)$, $P(\\mu | D)$ is from the previous iteration, exept for in the very first iteration when $\\xi(\\mu)$ will cancel because it's constant.\n",
    "\n",
    "This integral simplifies to the expectation of the posterior:\n",
    "\n",
    "$$ P(y_t | x_{t},x_{t-1},y_{t-1}) = \\int_{\\theta} P_{\\theta}(y_t) \\cdot d \\xi(\\theta|y_{t-1}) = \\frac{\\alpha_{t,x_t}}{\\alpha_{t,x_t} + \\beta_{t,x_t}}.$$\n",
    "\n",
    "Hence, we will not be computing the integral. Instead, we will update $\\alpha$ and $\\beta$ in a way that depends on the data. \n",
    "\n",
    "Now, focusing on $\\mu_1$, we will use the Beta-Bernoulli conjugate prior. It is a Bernoulli distribution, a binomial with $n=1$, where the probability of success at each trial is a random variable. This random variable is assumed to be beta distributed. Since Y is either 1 or 0 it is reasonable to assume that $Y|X$ is Bernoulli distributed.\n",
    "\n",
    "It is also convinient because of its conjugate prior property. We can now calculate $P( D | \\mu_1) = \\prod_{i=1}^{t} P(y_i | x_i ,x_{i-1}, y_{i-1}) $ beacuse we know that the marginal likelihood (posterior predictive distribution) is composed of a Bernoulli distribution and a beta distribution $ P(y_t | x_t , y_{t-1}) = \\int_{\\theta} P_{\\theta}(y_t|x_t) \\cdot \\xi(\\theta|x_{t-1},y_{t-1})$. For each iteration we get that $P_{\\mu} (D)$ is itself beta distributed.\n",
    "\n",
    "The same integral calculation is done for $P(D | \\mu_0)$ but now the marginal likelihood is assumed to be independent of the data.\n",
    "\n",
    "For convenience, instead of calculating $P(D |\\mu_1)$ directly, we will calculate $log(P(D|\\mu_1))$, and in the end do $e^{log(P(D|\\mu_1))}$ to obtain the desired probability.\n",
    "\n",
    "The calculation is done sequentially. For each iteration we have a new observation, a new set of genes. We continously update the posterior belief, and put this into a list. The belief gets updated through calculating the marginal likelihood in each iteration, and then taking the product between this marginal likelihood and all the previous marginal likelihoods. In the end we obtain the estimate $$ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_i}(D) \\cdot \\xi(\\mu_i)} $$.\n",
    "\n",
    "For each gene we then reject the null if $P(\\mu_1|D) > s$ for a given threshold $0 < s < 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265a36e",
   "metadata": {},
   "source": [
    "## The effect\n",
    "Once we have the most relevant genes we will look at the individual effect of each gene on symptoms, i.e the probability of having a symptom given that you have one of these genes. \n",
    "\n",
    "This will be done in a somewhat simplistic fashion. As described above, we assume a Beta-Bernoulli conjugate prior that leads to a beta distributed posterior belief with parameters $\\alpha$ and $\\beta$. We will update $\\alpha$ and $\\beta$ sequentially when reading through the data. For a given gene $x_i$ and symptom $y_i$, if $x_i = 1$, $\\alpha_i = \\alpha_{i-1} + 1$ if $y_i = 1$ and $\\beta_i = \\beta_{i-1} + 1$ if $y_i = 0$. This way we get the expected value of our posterior $$\\hat{p} = \\frac{\\alpha_0 + k}{\\alpha_0 + \\beta_0 + n} = \\frac{\\alpha}{\\alpha + \\beta}$$ where $k$ is the number of \"successes\" and $n$ is the number of observations where $x_i = 1$ and $\\alpha_0$ and $\\beta_0$ are the parameters of the prior ditribution. Given a large amount of data the choice for $\\alpha_0$ and $\\beta_0$ are not of much significance as we expect the results to converge to the \"true\" values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516b043",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ones we have the important fetures we want to look at wether these fetures contribute negativly or positivley.We tried to do that through computing $P(symptom=1|gene=1)$.If this probability is greater then $P(symptom=1|gene=0)=1-P(symptom=1|gene=1)$ then the effect should be negative. \n",
    "\n",
    "We calculated $P(symptom|gene=1)$ the bayesian way,like in 1.a. We start with i prior uniform distrbution $\\alpha=1$ $\\beta=1$. Update $p=\\frac{\\alpha}{\\alpha+\\beta}$.If $symptom=1$ we update $\\beta$ if $symptom=0$ we update $\\alpha$.\n",
    "\n",
    "From 1.b we know that the posterior befelif of $P(symptom|gene=1)$ is given by $Beta(\\alpha_{prior}+k,\\beta_{prior}+n-k)$.\n",
    "\n",
    "$k=0 , n=0$ becomes the prior dist.We update k, when we want to update $\\alpha$ and $\\beta$. The gene is constantly set to one,which means we are only looking at people have that gene.\n",
    "\n",
    "\n",
    "These probabilities where calculated for all the relevant genes.P(symptom=1|gene=1) was around 1.5% for these genes,which could have ment that these genes have a positive effect.When we tested features that where not selected we got arouund the same procentage.The conclution is that one gene in itself have no effect on someone getting a symptom or not.\n",
    "\n",
    "There might be such that a combination of genes together could have a postive or negative effect.This is much harder to find out,since we assume that in the data set there is not a lot of people with the same sequence of genes.\n",
    "\n",
    "The select feature also tests $ P(symptoms|genes) \\neq P(symptoms)$,separatly for each gene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de666c2",
   "metadata": {},
   "source": [
    "The generate binary_data function gets the inputs :N number columns,num_feutures of rows and a correlation vector.These numbers are put into the numpys random.choice functon which creats a matrix wich has dimensions N x num_feutures.Each element is eather 0 or one.This matrix is then used to creat a correlation between each column in the matrix and the target vector. The target vector is set to be a 0 vector. Each element in the target vector is flipped based  on what the value the product between a single feature vector and the random.choice is, which is 1 with p=corr and 0 with p=1-cor. Based on which feature that changes the value of the target to 1, in position i,there is now a correlation between that position in the target vector and feuture i.\n",
    "Or = is used because $(1 \\cup 1)=1, \\ \\ (1 \\cup 0)=1,(0 \\cup 1)=1,(0 \\cup 0)=0$.  The downside with this procedure is that if one creat correlation between to many features most of the elements in the target becomes 1.\n",
    "\n",
    "\n",
    "We Want to test wether the methods we use in problem 2 works as expected.To that we generate data which reflects the assumption,that if you are treated with a treatment and you had symptoms before the treatment,then after the treatment you have none. \n",
    "We therefore use the $\\oplus$ operator: $$1  \\  \\ \\ \\oplus \\  \\  1 \\ \\ =0$$   \n",
    "$$ = symptom before=1  \\  \\  \\oplus  \\  \\ treated = symptoms \\; after=1$$\n",
    "\n",
    " $$0 \\  \\  \\  \\oplus \\  \\  \\ 1= \\  \\  1$$,   $$= (symptom before=0  \\  \\  \\ \\oplus \\  \\  \\ treated =1) = (symptoms after=1)$$\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062feae",
   "metadata": {},
   "source": [
    "## Estimating the efficacy of vaccines\n",
    "\n",
    "We estimate the efficacy of the vaccines by\n",
    "$$ 100 \\cdot (1-IRR)$$\n",
    "where IRR is the ratio of the vaccinated incidence rate and not vaccinated incidence incidenes ([link](https://www.nejm.org/doi/full/10.1056/NEJMoa2034577)). This means that the relationship we model for each symptom is as given below:\n",
    "\n",
    "$r_v = P(symptom = 1 | vaccine = 1)$ and\n",
    "\n",
    "$r_n = P(symptom = 1 | vaccine = 0)$\n",
    "\n",
    "to obtain $IRR = 100 * [1 - r_v / r_n]$\n",
    "\n",
    "Our prior belief is that r_v and r_n is equal,for all symptoms.Before we have seen the data we assume that wether you have any sumptom or not is independent from wether you have taken the vaccine or not. Theirfore we assume that these probabilities are beta distributed with the same $\\alpha$ and $\\beta$ parameter.To estimate these parameters we firstfind the frequency of people having a certain symptom for both the vaccinated group and the non vaccinated group and devide these frequency by the total number of observation.This is know our estimate of the expected value for r_v and r_n.So we have.\n",
    "\n",
    "$$V=frequency \\ \\ \\ \\ of \\  \\ people \\ \\ having \\ \\ a \\ \\ certain \\ \\ symptom \\ \\ for \\ \\ the \\ \\ vaccinated$$\n",
    "$$NV=frequency \\ \\ of \\ \\ people \\ \\  having \\ \\  a  \\ \\ certain \\ \\  symptom \\ \\ for \\ \\  none \\ \\  vaccinated$$\n",
    "$$T=Total \\ \\ number \\ \\ of \\ \\ observations$$\n",
    "\n",
    "$$E[r_v]=\\frac{\\alpha}{\\alpha+\\beta}=\\frac{V}{T} $$ \n",
    "$$E[r_n]=\\frac{\\alpha}{\\alpha+\\beta}=\\frac{NV}{T}$$\n",
    "\n",
    "Our prior belief is that $p=\\frac{V}{T}=\\frac{NV}{T}$.\n",
    "\n",
    "So:\n",
    "\n",
    "$$E[r_v]=E[r_n]=\\frac{\\alpha}{\\alpha+\\beta}=\\frac{V}{T} $$ \n",
    "\n",
    "\n",
    "The equation to solve in order to get the  $\\alpha$ and the $\\beta$ values for our prior belief is for example:\n",
    "\n",
    "$$\\frac{\\alpha}{\\alpha+\\beta}=\\frac{V}{T} $$\n",
    "\n",
    "Setting $\\beta=1$ we get $\\alpha=\\frac{\\beta*p}{1-p}$.\n",
    "\n",
    "we set $ \\frac{V}{T}= 0.02 $ as our guess before seening the data. probability 0.02 for getting a symptom, indepedent of what symptom. We set beta to be 1 and $ \\alpha<1$ beacause this distribution will have most of its mass around 0. In other words our prior belief is that the random variables r_v and r_n takes a value around 0 with a large probability. The probability of getting a symptom independent of vaccinated or not is very  likely to be around 0. When we get the data we can easly be proven wrong. The choosen posterior distrbution will also confurm that 0.02 is a good choice.\n",
    "\n",
    "After we get the data 0.02 could be a horrible choice(have a low probability in the prosterior dist),and $\\frac{V}{T}\\neq \\frac{NV}{T}$.\n",
    "\n",
    "We have that $Posterior \\propto Likelihood * Prior$.We are asuming that the prior comes from a beta distribution. The likelihhood is the likelihood of observing all the combinations of the observations.Our observations are sequences of 1 and 0's.Our likelihood is theirfore binomial dist.This makes the posterior beta dist.The prior and the posterior has the same dist.\n",
    "\n",
    "\n",
    "\n",
    "$Posterior \\propto Likelihood * Prior={n \\choose k}\\theta^k(1-\\theta)^{n-k} \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1} \\propto \\theta^{\\alpha+k-1}(1-\\theta)^{\\beta+n-k-1}$ which is beta dist.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We use these posterior parameters to genrate N numbers of random variables,both for the vaccinated group and the none vaccinated group(monte carlo),in order to find a 95% credible intterval for our estimated efficacy of the vaccine on all the symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc73d8",
   "metadata": {},
   "source": [
    "## Estimating the probability of vaccination side-effects.\n",
    "\n",
    "Using the Bayes theorem, we will estimate the probability of vaccination side-effects. In other words, the probability of getting symptoms given that a person is vaccinated and has tested negative.\n",
    "$$p_1 = P(symptom | vaccine,covid') = \\frac{P(symptom \\cap vaccine,covid')}{P(vaccine,covid')} $$\n",
    "$$p_2 = P(symptom | vaccine',covid') = \\frac{P(symptom \\cap vaccine',covid')}{P(vaccine',covid')} $$\n",
    "\n",
    "We want to test the following hypothesis:\n",
    "$$ h_0: p_1 - p_2 \\leq 0 $$\n",
    "$$h_a: p_1 - p_2 > 0 $$\n",
    "\n",
    "We make a confidence intervall for each symptom, and reject the null hypothesis if confidence intervall does not include zero.\n",
    "\n",
    "**A large-sample 95% confidence interval for $p_1 - p_2$**:\n",
    "\n",
    "In this task it seems appropiate to estimate confidence intervalls instead of doing the task of comparison through hypotesis testing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The variables X and Y  represents the number of individuals in each sample having a certain  characteristic that defines $p_1$ and $p2$.Provided the population sizes are much larger than the sample sizes, the distribution\n",
    "of X can be choosen to be binomial with parameters m and $p_1$, and similarly, Y is choosen\n",
    "to be a binomial variable with parameters n and $p_2$. The samples are assumed to be independent of each other.Therefore X and Y are independent rv’s.\n",
    "\n",
    "The estimator for $ p_1-p_2 $, the difference in population proportions, is\n",
    "the  difference in sample proportions $\\frac{X}{m} - \\frac{Y}{n}$ .  $ \\hat{p_1} = \\frac{X}{m}$ and\n",
    "$\\hat{p_2} = \\frac{Y}{m}$, the estimator of $ p_1-p_2 $ can be expressed as $\\hat{p_1} - \\hat{p_2}$.\n",
    "\n",
    "$E[\\hat{p_1} - \\hat{p_2}]=p_1-p_2$ so $\\hat{p_1} - \\hat{p_2}$ is an unbiased estimate of $p_1-p_2$ \n",
    "\n",
    "$\\hat{p_1}=\\frac{X}{m}$ and $\\hat{p_2}=\\frac{y}{n}$ are aproximately normal distributed when m and n are large.\n",
    "\n",
    "\n",
    "Refrence: Modern Mathematical Statistic with applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f1317",
   "metadata": {},
   "source": [
    "## The effect of treatments on alleviating symptoms\n",
    "\n",
    "We are not interested in the outcomes for individuals who did not have any symptoms neither before nor after the treatment,since these individuals dont tell us anything about wether one had a positve of negative effect of the treatment.\n",
    "\n",
    "We do this modelling task in a similar way that we did the modelling for vaccine efficacy. Since we now have data from before and after a treatment, we calculate the ratio of people who still have symptoms after treatment to the people who had symptoms before treatment for both the treated group and the control group. \n",
    "\n",
    "\n",
    "\n",
    "We estimate the efficacy of the treatments based on this ration\n",
    "\n",
    "\n",
    "$t_1 = P(symptom = 1 | treatment = 1)$ after treatment, $t_0 = P(symptom = 1 | treatment = 1) $ before treatment.\n",
    "\n",
    "$n_1 = P(symptom = 1 | treatment = 0)$ after treatment, $n_0 = P(symptom = 1 | treatment = 0) $ before treatment\n",
    "\n",
    "$r_t = t_1 / t_0$ and\n",
    "\n",
    "$r_n = n_1 / n_0$\n",
    "\n",
    "\n",
    "$$ ratio=\\frac{r_n}{r_t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb0803",
   "metadata": {},
   "source": [
    "## The modelling\n",
    "\n",
    "We start by importing the libraries and loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3898c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import btdtri\n",
    "import random\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b75e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = pd.read_csv(\"observation_features.csv\")\n",
    "treat_data = pd.read_csv(\"treatment_features.csv\")\n",
    "action_data = pd.read_csv(\"treatment_actions.csv\")\n",
    "outcome_data = pd.read_csv(\"treatment_outcomes.csv\")\n",
    "\n",
    "cols = (['Covid-Recovered', 'Covid-Positive', 'No-Taste/Smell', 'Fever', 'Headache', 'Pneumonia', 'Stomach', 'Myocarditis', 'Blood-Clots', 'Death',\n",
    "        'Age', 'Gender', 'Income'] +\n",
    "         [f'Gene_{i+1:03}' for i in range(128)] +\n",
    "         ['Asthma', 'Obesity', 'Smoking', 'Diabetes', 'Heart disease', 'Hypertension',\n",
    "         'Vacc_1', 'Vacc_2', 'Vacc_3'])\n",
    "\n",
    "obs_data.columns = cols\n",
    "treat_data.columns = cols\n",
    "outcome_data.columns = cols[:10]\n",
    "action_data.columns = ['Treatment_1', 'Treatment_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e40653",
   "metadata": {},
   "source": [
    "## The pipelines\n",
    "\n",
    "In this section we indroduce **Pipeline_observational**. This pipeline will be used throughout problem. It contains the methods for modelling the effective genes, finding efficacy of the vaccines and the estimating the probability of sideeffects for all vaccines. We also introduce the **Pipeline_treatment** which contains methods for estimating the efficacy for treatments.\n",
    "\n",
    "The pipelines will be run with generated data and tested before we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9f11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline_observational():\n",
    "\n",
    "    def __init__(self, obs_data=None):\n",
    "        self.obs_data = obs_data\n",
    "        self.symptoms = obs_data.iloc[:,:10]\n",
    "        self.genes = obs_data.iloc[:, 10:139]\n",
    "        #self.vaccine = obs_data[:,147:]\n",
    "\n",
    "    def run_select_features(self, genes, symptom, threshold):\n",
    "        \"\"\"This function finds the selected features, then runs BIC test in order \n",
    "        to see whether the model with selected features are better than the full model\"\"\"\n",
    "        \n",
    "        self.best_features = best_features = self.select_features(genes,symptom,threshold)\n",
    "        self.important_genes = [col for col in genes.iloc[:,best_features].columns]\n",
    "\n",
    "    def select_features(self, genes, symptoms, threshold):\n",
    "        \"\"\" Select the most important features of a data set, where X (2D)\n",
    "        contains the feature data, and Y (1D) contains the target\n",
    "        \"\"\"\n",
    "        X, Y = np.array(genes), np.array(symptoms)\n",
    "        n_features = X.shape[1]\n",
    "        n_data =  X.shape[0]\n",
    "        alpha_b = np.ones([n_features, 2 ])\n",
    "        beta_b = np.ones([n_features, 2])\n",
    "        log_p = np.zeros(n_features)\n",
    "\n",
    "        log_null = 0\n",
    "        alpha = 1\n",
    "        beta = 1\n",
    "        for t in range(n_data):\n",
    "            p_null = alpha / (alpha + beta)\n",
    "            log_null += np.log(p_null)*Y[t] + np.log(1-p_null)*(1 - Y[t])\n",
    "            alpha += Y[t]\n",
    "            beta += (1 - Y[t])\n",
    "            for i in range(n_features):\n",
    "                x_ti = int(X[t,i])\n",
    "                p = alpha_b[i, x_ti] / (alpha_b[i, x_ti] + beta_b[i, x_ti])\n",
    "                log_p[i] += np.log(p)*Y[t] + np.log(1-p)*(1 - Y[t])\n",
    "                alpha_b[i, x_ti] += Y[t]\n",
    "                beta_b[i, x_ti] += (1 - Y[t])\n",
    "        log_max=np.mean(log_p)\n",
    "        log_max2=np.mean(log_null)\n",
    "        log_p=log_p-log_max\n",
    "        log_null=log_null-log_max2\n",
    "        p = 1 / (np.exp(log_null - log_p) + 1)\n",
    "        return [i for i in range(n_features) if p[i] > threshold]\n",
    "    \n",
    "    def estimate_gene_effect(self,symptom, genome):\n",
    "        \"\"\"Given a genome and a symptom, we estimate the probability of having a symptom from the data\"\"\"\n",
    "        symptom, genome = np.array(symptom), np.array(genome)\n",
    "        alpha = 1\n",
    "        beta = 1\n",
    "        for t in range(genome.shape[0]):\n",
    "            if genome[t] == 1:\n",
    "                alpha += symptom[t]\n",
    "                beta += (1 - symptom[t])\n",
    "\n",
    "        return alpha/(alpha+beta)\n",
    "\n",
    "    def estimate_vaccine_efficacy(self, group_pos: pd.DataFrame, group_neg: pd.DataFrame, symptom, prior_probs):\n",
    "        \"\"\" Given a dataframe group_pos (vaccinated and covid positive) and group_neg (not vaccinated and covid postive) we estimate the efficacy of the vaccines\"\"\"\n",
    "        \n",
    "        if isinstance(symptom, int):\n",
    "            symptom_index = symptom\n",
    "            symptom_name = group_pos.keys()[symptom]\n",
    "        else:\n",
    "            symptom_name = symptom\n",
    "            symptom_index = list(group_pos.keys()).index(symptom)\n",
    "\n",
    "        group_pos_count = np.sum(group_pos[symptom_name] * group_pos.iloc[:,1])\n",
    "        group_neg_count = np.sum(group_neg[symptom_name] * group_neg.iloc[:,1])\n",
    "\n",
    "        v = group_pos_count/len(group_pos)\n",
    "        n_v = group_neg_count/len(group_neg)\n",
    "\n",
    "        if n_v == 0:\n",
    "            print(f'{v}, {n_v}: Division by zero')\n",
    "            return\n",
    "\n",
    "        IRR = v/n_v\n",
    "\n",
    "        efficacy = 100*(1- IRR)\n",
    "\n",
    "        N = 100_000\n",
    "        beta = 1\n",
    "        p = prior_probs[symptom_index]\n",
    "        alpha = beta*p/(1-p)\n",
    "\n",
    "        samples_group_pos = stats.beta.rvs(alpha + group_pos_count, beta + len(group_pos) - group_pos_count, size=N)\n",
    "        samples_group_neg = stats.beta.rvs(alpha + group_neg_count, beta + len(group_neg) - group_neg_count, size=N)\n",
    "\n",
    "        samples_ve = 100 * (1 - samples_group_pos/samples_group_neg)\n",
    "        lower = np.percentile(samples_ve, 2.5)\n",
    "        upper = np.percentile(samples_ve, 97.5)\n",
    "    \n",
    "        print(f'{symptom_name:15s}: {efficacy:3.3f} - ({lower:3.3f}, {upper:3.3f})')\n",
    "    \n",
    "    def print_vaccine_efficacy(self, symptoms: pd.DataFrame, vaccinated: pd.DataFrame, not_vaccinated: pd.DataFrame):\n",
    "        \"\"\"Given a set of vaccinated and unvaccinated data, we estimate the efficacy of all vaccines together and then one by one \"\"\"\n",
    "        for i, s in enumerate(symptoms.columns):\n",
    "            self.estimate_vaccine_efficacy(vacced,un_vacced,i,prior_probs)\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "        vaccination_types = [vaccinated[vaccinated.iloc[:,v] == 1].iloc[:,v] for v in range(vaccinated.shape[1])]\n",
    "        vaccination_types.colums = [f'vaccine{i}' for i in range(vaccinated.shape[1])]\n",
    "        \n",
    "        for i, vaccine in enumerate(vaccination_types):\n",
    "            print(vaccination_types.columns[i])\n",
    "            for j, s in enumerate(symptoms.columns):\n",
    "                self.find_vaccine_efficacy(vaccination_types[j],not_vaccinated,s,prior_probs)\n",
    "            print(\"\")\n",
    "        \n",
    "        \n",
    "    def estimate_side_effects(self, vacced_neg, un_vacced_neg, start, end):\n",
    "        \"\"\"Given a set of vaccinated and unvaccinated data, we estimate the efficacy of the vaccines\"\"\"\n",
    "\n",
    "        stats = pd.DataFrame(index=vacced_neg.keys()[start:end],\n",
    "                          columns = (\"p1 (%)\", \"p2 (%)\", \"Diff (%)\", \"Confidence Interval (%)\", \"Null Hypothesis\", ),\n",
    "                         )\n",
    "\n",
    "        for i in range(start, end):\n",
    "            symptom = vacced_neg.keys()[i]\n",
    "            p1 = vacced_neg.sum()[i] / vacced_neg.shape[0]\n",
    "            p2 = un_vacced_neg.sum()[i] / un_vacced_neg.shape[0]\n",
    "\n",
    "\n",
    "            lower = (p1-p2 - 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "            higher = (p1-p2 + 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "\n",
    "            p1, p2, lower, higher = p1 * 100, p2 * 100, lower * 100, higher * 100\n",
    "\n",
    "            stats.loc[symptom] = np.array([round(p1, 4), round(p2, 4), round(p1 - p2, 4), (round(lower, 4), round(higher, 4)),\n",
    "                               \"rejected\" if lower>0 else \"not rejected\", ],dtype=object)\n",
    "\n",
    "\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ca045",
   "metadata": {},
   "source": [
    "### Treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61c7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline_treatment():\n",
    "    \n",
    "    def __init__(self,treat_data,action_data,outcome_data):\n",
    "        \"\"\"Given the pre treatment symptoms, the treatment action and post treatment symptoms, we slice the data into actionstypes and outcome types \"\"\"\n",
    "\n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore')\n",
    "\n",
    "        self.treat_data = treat_data\n",
    "        self.action_data = action_data\n",
    "        self.outcome_data = outcome_data\n",
    "\n",
    "        new_treat_data = treat_data[((np.sum(treat_data.iloc[:,2:10],axis=1) > 0.0) | np.sum(outcome_data.iloc[:,2:10],axis=1) > 0.0)]\n",
    "        self.group_first = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
    "        self.group_second = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
    "        self.group_both = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
    "        self.group_none = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]\n",
    "\n",
    "        new_outcome_data = outcome_data[((np.sum(treat_data.iloc[:,2:10],axis=1) > 0.0) | np.sum(outcome_data.iloc[:,2:10],axis=1) > 0.0)]\n",
    "        self.outcome_first = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
    "        self.outcome_second = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
    "        self.outcome_both = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
    "        self.outcome_none = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]\n",
    "       \n",
    "        self.prior_probs= [(np.sum(new_treat_data[sym]) + np.sum(new_outcome_data[sym])) / (len(new_treat_data) * 2) for sym in outcome_data.columns][2:]\n",
    "\n",
    "    def print_treatment_efficacy(self):\n",
    "        outcome_first, outcome_second, outcome_both, outcome_none, group_first, group_second, group_both, group_none = self.outcome_first, self.outcome_second, self.outcome_both, self.outcome_none, self.group_first, self.group_second, self.group_both, self.group_none\n",
    "        print(self.prior_probs)\n",
    "        \n",
    "        for outcome_treated, pre_treated, treatment in zip([outcome_first, outcome_second, outcome_both],[group_first, group_second, group_both],['Treatment 1', 'Treatment 2', 'Both treatments']):\n",
    "            print(f\"{treatment} efficacy:\")\n",
    "            results = {}\n",
    "            for i, key in enumerate(self.outcome_data.keys()[2:]):\n",
    "                eff, ci = self.treatment_efficacy(outcome_treated, pre_treated, outcome_none, group_none, self.prior_probs[i], key,log=False)\n",
    "                results[key] = eff; results['95% CI'] = ci\n",
    "            \n",
    "            print(pd.DataFrame(results).T)\n",
    "\n",
    "\n",
    "    def find_alpha(self, beta,p):\n",
    "        \"\"\" Given beta and a mean probability p, compute and return the alpha of a beta distribution. \"\"\"\n",
    "        return beta*p/(1-p)\n",
    "\n",
    "    def treatment_efficacy(self, outcome_treated, precondition_treated, outcome_untreated, precondition_untreated, p, symptom_name, log=True):\n",
    "        \n",
    "        group_pos_count = np.sum(outcome_treated[symptom_name])\n",
    "        group_neg_count = np.sum(outcome_untreated[symptom_name])\n",
    "\n",
    "        group_pos_total = np.sum(precondition_treated[symptom_name])\n",
    "        group_neg_total = np.sum(precondition_untreated[symptom_name])\n",
    "\n",
    "        if any(v == 0 for v in (group_pos_total, group_neg_total, group_neg_count)):\n",
    "            print(f'{symptom_name:15s}: Division by zero - not enough data to compute efficacy' )\n",
    "            return\n",
    "\n",
    "        v = group_pos_count / group_pos_total\n",
    "        n_v = group_neg_count / group_neg_total\n",
    "        IRR = v/n_v\n",
    "\n",
    "        efficacy = 100 * (1- IRR)\n",
    "\n",
    "        N=100_000\n",
    "        beta = 1\n",
    "        alpha = beta*p/(1-p)\n",
    "\n",
    "        samples_group_pos = stats.beta.rvs(alpha + group_pos_count, beta + len(outcome_treated) - group_pos_count, size=N)\n",
    "        samples_group_neg = stats.beta.rvs(alpha + group_neg_count, beta + len(outcome_untreated) - group_neg_count, size=N)\n",
    "\n",
    "        samples_ve = 100 * (1 - samples_group_pos/samples_group_neg)\n",
    "        lower = np.percentile(samples_ve, 2.5)\n",
    "        upper = np.percentile(samples_ve, 97.5)\n",
    "        \n",
    "\n",
    "        \n",
    "        if log is True:\n",
    "            print(f'{symptom_name:15s}: {efficacy:7.3f} - 95% CI: ({lower:3.3f}, {upper:3.3f})')\n",
    "\n",
    "        return efficacy, (lower, upper)\n",
    "    \n",
    "    \n",
    "    def plot_symptoms(self):\n",
    "        pre_treatment = {}\n",
    "        treatment_one = {}\n",
    "        treatment_two = {}\n",
    "        treatment_both = {}\n",
    "        treatment_none = {}\n",
    "\n",
    "        for symptom_name in self.treat_data.columns[2:10]:\n",
    "            pre_treatment[symptom_name] = np.sum(self.treat_data[symptom_name])\n",
    "            treatment_one[symptom_name] = np.sum(self.outcome_first[symptom_name])\n",
    "            treatment_two[symptom_name] = np.sum(self.outcome_second[symptom_name])\n",
    "            treatment_both[symptom_name] = np.sum(self.outcome_both[symptom_name])\n",
    "            treatment_none[symptom_name] = np.sum(self.outcome_none[symptom_name])\n",
    "\n",
    "        x_axis = np.arange(len(pre_treatment.keys()))\n",
    "        plt.bar(x_axis-0.24, pre_treatment.values(), width = 0.12, color='b', label = \"Pre treatment\")\n",
    "        plt.bar(x_axis-0.12, treatment_one.values(), width = 0.12, color='g', label = \"Treatment 1\")\n",
    "        plt.bar(x_axis, treatment_two.values(), width = 0.12,color='r', label = \"Treatment 2\")\n",
    "        plt.bar(x_axis+0.12, treatment_both.values(), width = 0.12,color='purple', label = \"Both treatments\")\n",
    "        plt.bar(x_axis+0.24, treatment_none.values(), width = 0.12,color='pink', label = \"No treatment\")\n",
    "        plt.xticks(x_axis, self.treat_data.columns[2:10], rotation=90)\n",
    "        plt.ylabel(\"Number of occurances\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46062f6",
   "metadata": {},
   "source": [
    "Most of the the individuals did'nt have any symptoms. We can theirfore see that the classifier we used failed to classify all the individuals that did have symptoms.The only way one can then determain if our select feuture method works or not is using generated data,that are highly squed toward individuals having symptoms.\n",
    "\n",
    "Our result also shows that genes in them selves are not very good determiners for wether somebody that are covid positive gets a certain symptom or not. These types of conclutions can only be made using the original data. \n",
    "\n",
    "To see if their is somthing \"wrong\" with the algorithm one could try different algorithms.If the result still is the same, \n",
    "genes in them selves are not very good determiners for wether somebody that are covid positive gets a certain symptom or not.\n",
    "\n",
    "\n",
    "Only use generated data to confirm wether the select feuture method works as it is expected to work.You cant alter reality as you want,generating data to force feutures to be significant,does not reflect reality,it reflects what you want reality to be.\n",
    "\n",
    "Could test gender and comorbidities which also is binary variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078d6da",
   "metadata": {},
   "source": [
    "## Generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33b6e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_data(num_features, N, correlation=[0.9, 0.5]):\n",
    "    data = np.random.choice(2, size=(N, num_features))\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Target\"] = np.zeros(N).astype(int)\n",
    "    for i, cor in enumerate(correlation):\n",
    "        if i >= num_features:\n",
    "            break\n",
    "\n",
    "        df[\"Target\"] |= df.iloc[:, i] * np.random.choice(2, size=N, p=[(1-cor), cor])\n",
    "\n",
    "    return df.iloc[:, :num_features], df[\"Target\"]\n",
    "\n",
    "def generate_genomes_symptoms(random_indecies):\n",
    "    cor = [0.2 for _ in range(128)]\n",
    "    for r in random_indecies:\n",
    "        cor[r] = 0.9\n",
    "    X,y = generate_binary_data(128,100_000, correlation=cor)\n",
    "    X.columns = [f'Gene_{i+1:03}' for i in range(128)]\n",
    "    y.columns = cols[1]\n",
    "    return X,y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25492324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vaccine_data():\n",
    "    sym_g = np.random.choice(2,size=[100_000,10])\n",
    "    y = np.random.choice(2,size=[100_000,1])\n",
    "\n",
    "    vac_g = np.zeros([100_000,3])\n",
    "    for i,v in enumerate(y):\n",
    "        if v == 1:\n",
    "            rand_ind = random.randint(0,2)\n",
    "            vac_g[i][rand_ind] = 1\n",
    "\n",
    "    vac_g = pd.DataFrame(vac_g,columns = ['Vacc_1', 'Vacc_2', 'Vacc_3'])\n",
    "    sym_g = pd.DataFrame(sym_g,columns = ['Covid-Recovered', 'Covid-Positive', 'No-Taste/Smell', 'Fever', 'Headache', 'Pneumonia', 'Stomach', 'Myocarditis', 'Blood-Clots', 'Death'])\n",
    "\n",
    "    vacced = sym_g[np.sum(vac_g.iloc[:,-3:], axis=1) == 1]\n",
    "    un_vacced = sym_g[np.sum(vac_g.iloc[:,-3:], axis=1) == 0]\n",
    "    prior_probs_generated = [np.sum(sym_g.iloc[:,i]) / len(sym_g) for i, key in enumerate(sym_g.columns)]\n",
    "    return vacced, un_vacced, prior_probs_generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0d4d3",
   "metadata": {},
   "source": [
    "### The experiment setup\n",
    "\n",
    "In this section we will set up the experiment by running the pipeline with different generated data and see whether it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc0c8533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run nr: 0\n",
      "Run nr: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xc/9tjchlhd1yn758nk26c1m1dc0000gn/T/ipykernel_23319/2331037690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgenomes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymptom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_genomes_symptoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_indecies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline_observational\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_select_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenomes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymptom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xc/9tjchlhd1yn758nk26c1m1dc0000gn/T/ipykernel_23319/4257302061.py\u001b[0m in \u001b[0;36mrun_select_features\u001b[0;34m(self, genes, symptom, threshold)\u001b[0m\n\u001b[1;32m      5\u001b[0m         to see whether the model with selected features are better than the full model\"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymptom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportant_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xc/9tjchlhd1yn758nk26c1m1dc0000gn/T/ipykernel_23319/4257302061.py\u001b[0m in \u001b[0;36mselect_features\u001b[0;34m(self, X, Y, threshold)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mx_ti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mlog_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0malpha_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Run nr: {i}')\n",
    "    random_indecies = random.sample(range(128), 20)\n",
    "    genomes,symptom = generate_genomes_symptoms(random_indecies)\n",
    "    pipe = Pipeline_observational()\n",
    "    pipe.run_select_features(genomes,symptom,0.8)\n",
    "    \n",
    "    for i in pipe.best_features:\n",
    "        if i not in random_indecies:\n",
    "            print(f'{i}: fail')\n",
    "\n",
    "\n",
    "    #kjøre efficacy\n",
    "    #kjøre sideeffects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ea248",
   "metadata": {},
   "source": [
    "## Running pipeline on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae06177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21951219512195122, 0.12804878048780488, 0.024390243902439025, 0.16158536585365854, 0.024390243902439025, 0.057926829268292686, 0.15548780487804878, 0.054878048780487805]\n",
      "Treatment 1 efficacy:\n",
      "Stomach        : Division by zero - not enough data to compute efficacy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e8466de5992e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpipe_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline_treatment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreat_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcome_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpipe_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_treatment_efficacy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpipe_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_symptoms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-dcf395786188>\u001b[0m in \u001b[0;36mprint_treatment_efficacy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutcome_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0meff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtreatment_efficacy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome_treated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_treated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcome_none\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_none\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meff\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'95% CI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "pipe_t = Pipeline_treatment(treat_data, action_data, outcome_data)\n",
    "\n",
    "pipe_t.print_treatment_efficacy()\n",
    "pipe_t.plot_symptoms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e019c7c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "435b141e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 68.6 MiB for an array with shape (150, 59963) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1b90da028ea5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpipe_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline_observational\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvacced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvacced_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvacced\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvacced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvacced_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvacced\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvacced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2895\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2949\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2950\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2951\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2953\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3361\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m         \"\"\"\n\u001b[1;32m-> 3363\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3350\u001b[0m         new_data = self._mgr.take(\n\u001b[1;32m-> 3351\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3352\u001b[0m         )\n\u001b[0;32m   3353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"take\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m-> 1457\u001b[1;33m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m         )\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     ),\n\u001b[0;32m   1300\u001b[0m                 )\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             ]\n\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     ),\n\u001b[0;32m   1300\u001b[0m                 )\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             ]\n\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         new_values = algos.take_nd(\n\u001b[1;32m-> 1256\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m         )\n\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 68.6 MiB for an array with shape (150, 59963) and data type float64"
     ]
    }
   ],
   "source": [
    "pipe_o = Pipeline_observational(obs_data)\n",
    "\n",
    "vacced = obs_data[np.sum(obs_data.iloc[:,-3:], axis=1) == 1]\n",
    "vacced_neg = vacced[vacced.iloc[:,1]==0]\n",
    "vacced_pos = vacced[vacced.iloc[:,1]==1]\n",
    "\n",
    "un_vacced = obs_data[np.sum(obs_data.iloc[:,-3:], axis=1) == 0]\n",
    "un_vacced_neg = un_vacced[un_vacced.iloc[:,1]==0]\n",
    "un_vacced_pos = un_vacced[un_vacced.iloc[:,1]==1]\n",
    "prior_probs= [np.sum(obs_data.iloc[:,i]) / len(obs_data) for i, key in enumerate(obs_data.iloc[:,2:10].columns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35867339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-Taste/Smell\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-5a75e7434559>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymptom_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrelevant_genes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymptoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Relevant genes: {relevant_genes}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'Probability of getting {s} if {relevant_genes[i]}: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mpipe_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate_gene_effect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymptoms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrelevant_genes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelevant_genes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-54914a0b48a6>\u001b[0m in \u001b[0;36mselect_features\u001b[1;34m(self, vaccinated, symptoms, threshold)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mx_ti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbeta_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mlog_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0malpha_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ti\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "symptom_names = ['Covid-Recovered', 'Covid-Positive', 'No-Taste/Smell', 'Fever', 'Headache', 'Pneumonia', 'Stomach', 'Myocarditis', 'Blood-Clots', 'Death']\n",
    "symptoms = obs_data.iloc[:,2:10]\n",
    "genes = obs_data.iloc[:, 10:139]\n",
    "\n",
    "for s in symptom_names[2:10]:\n",
    "    print(s)\n",
    "    relevant_genes = pipe_o.select_features(genes, symptoms, 0.8)\n",
    "    print(f'Relevant genes: {relevant_genes}')\n",
    "    print([f'Probability of getting {s} if {relevant_genes[i]}: ' + {pipe_o.estimate_gene_effect(symptoms[s], genes.iloc[relevant_genes[i]])} for i in enumerate(relevant_genes)])\n",
    "\n",
    "pipe_o.run_vaccine_efficacy(obs_data.iloc[:,2:10], vacced, un_vacced)\n",
    "pipe_o.estimate_side_effects(vacced_neg, un_vacced_neg, 1, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f2668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9001319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "319fbb42ef2dc1eb7d6b76c74f00544471cc0c37bd0baf366634b03c03d1e04a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
