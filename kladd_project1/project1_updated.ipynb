{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d90a2e",
   "metadata": {},
   "source": [
    "# Project 1: Data analysis\n",
    "\n",
    "## 1a) Bayesian approch\n",
    "\n",
    "In order to predict the effect of genes on symptoms, we will use a simple Bayesian model. We consider these hypothesis:\n",
    "\n",
    "$$\\mu_0: P(symptoms|genes) = P(symptoms)$$\n",
    "$$\\mu_1: P(symptoms|genes) \\neq P(symptoms)$$\n",
    "\n",
    "In order words, does the genes have any effect on the symptoms or not? If it does, which genomes are the most relevant for the preventing the symptoms? \n",
    "\n",
    "\n",
    "We let Y be the symptoms and our X the genes. Y is an 8 bit vector for each observation,with 1 or zero for each bit. X is an 128 with the same charectaristic as Y.\n",
    "\n",
    "\n",
    "The probability distribution of $ Y $ depends on an unknown parameter that we assume to be stochastic. We call this unknown parameter $\\theta$ or $ p $. \n",
    "\n",
    "The formulation under is an alternative formulation of the the previous hypotesis. Does the parameter that the probability distribution of Y depend on, depend on X or not. $ \\mu_0 $, our null, says that it does not. $\\mu_1 $, the alternative hypothesis claims it does. We assume the Beta-Bernoulli model:\n",
    " \n",
    "$$\\mu_0: \\theta^0 \\sim Beta(\\alpha^0 , \\beta^0) ,  \\ \\ \\  Y | \\theta^0  $$\n",
    "$$\\mu_1: \\theta^{1,x_t} \\sim Beta(\\alpha^{1,x_t} , \\beta^{1,x_t}) , \\ \\ \\ y_t | x_t \\sim bernoulli(\\theta^{1,x_t}) $$\n",
    " \n",
    "\n",
    "Given the data, D, we try to estimate\n",
    "\n",
    "$$ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_1}(D) \\cdot \\xi(\\mu_1)} $$\n",
    "\n",
    "We can either set $P(\\mu | D)$ to mean $P(\\mu_1 | D)$ or  $P(\\mu_0 | D)$ depending on which hypothesis we want to check the posterior belief of. \n",
    "\n",
    "We let $P_{\\mu} (D) = P(\\mu |D)$, $D = (x_t, y_t,x_{t-1},y_{t-1})_{t=1} ^T $ for a spesific gene, and let $x_t$ be the value of the gene for observation t (0  or 1), $x_{t-1}$ is a vector of all the previous values of the previous observation up to t-1,  $y_t$ is the the value of symptom Y for observation t (0 or 1),$y_{t-1}$ is a vector of all the previous values of the previous observations including t-1 and $\\mu$ is one of the hypothesis in the set {$\\mu_1$,$\\mu_0$}.  We assume that the different observations(rows) of the data are independent of each other. This gives us:\n",
    "$$ P_{\\mu}(D) = P(y_1,...,y_t \\cup x_1,...,x_t)$$\n",
    "\n",
    "$$ = \\prod_{i=1}^{t} P(y_i | x_i,x_{i-1} , y_{i-1}) $$\n",
    "\n",
    "\n",
    "With these assumptions, we can estimate the terms in the $P_{\\mu} (D)$ by \n",
    "$$ P(y_t | x_t,x_{t-1} , y_{t-1}) = \\int_{\\theta} P_{\\theta}(y_t|x_t) \\cdot \\xi(\\theta|x_{t-1},y_{t-1})$$\n",
    "\n",
    "We calculate the likehood of adding a new observation(row) using this formula. It works if we assume that the the next observation is independent from the previous observations.\n",
    "\n",
    "\n",
    "This is the marginal likelihood(posterior predictive distribution) which is a compound distribution,which is used to calculate $P(y_t | x_{t},x_{t-1}, y_{t-1})$. The probabilty $P(y_t | x_{t})$ is stochastic in $\\theta$, so we have to integrate over all values of $\\theta$. Every time a new observation is added we calculate $P(y_t | x_{t},x_{t-1}, y_{t-1})$,and recalculate $$ = \\prod_{i=1}^{t} P(y_i | x_i ,x_{i-1}, y_{i-1}) $$. \n",
    "\n",
    "So to calculate $$ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_i}(D) \\cdot \\xi(\\mu_i)} $$, we are sequentially updating our belief every time a new observation is added. For every update $\\xi(\\mu)$, $P(\\mu | D)$ is from the previous iteration, exept for the first one. $\\xi(\\mu)$ will cancel because it's constant.\n",
    "\n",
    "This integral simplifies to:\n",
    "\n",
    "$$ P(y_t | x_{t},x_{t-1},y^{t-1}) = \\int_{\\theta} P_{\\theta}(y_t) \\cdot d \\xi(\\theta|y^{t-1}) = \\frac{\\alpha_{t,x_t}}{\\alpha_{t,x_t} + \\beta_{t,x_t}}$$\n",
    "\n",
    "\n",
    "Looking at $\\mu_1$ we are using the Beta-Bernoulli distribution. Its a binomial distribution where the probability of success at each of n trials is not fixed but comes from a Beta distribution. The Bernoulli distribtuion is a special case of the binomial distribution, where number of trials is equal to 1.\n",
    "\n",
    "We are doing this because our y's are either 1 or 0. It is then reasonable to assume that $Y|X$ is Bernoulli distributed.\n",
    "\n",
    "It is also conviniant because of its conjugate prior property. Now we can calculate $P( D | \\mu_1) = \\prod_{i=1}^{t} P(y_i | x^i ,x^{i-1}, y^{i-1}) $ beacuse we know that the marginal likelihood (posterior predictive dist) is composed of a Bernoulli distribution and a Beta dist $ P(y_t | x^t , y^{t-1}) = \\int_{\\theta} P_{\\theta}(y_t|x_t) \\cdot \\xi(\\theta|x^{t-1},y^{t-1})$, which is beta distributed. For each iteration we end up getting that $P_{\\mu} (D)$ is Beta distributed.\n",
    "\n",
    "The same integral calculation is done for $P(D | \\mu_0)$ but now the marginal likelihood is independent of the data.\n",
    "\n",
    "Instead of calculating $P(D |\\mu_1) = \\prod_{i=1}^{t} P(y_i | x_i ,x_{i-1}, y_{i-1})$, we can first calculate $log(P(  D|\\mu_1))$ and then do $e^{log(P(D|\\mu_1))}$,same for $P(D | \\mu_0)$.\n",
    "\n",
    "To summarize, we have a set of hypotesis. In this case two. We want to find how accurate they are, so we have a prior beleif on the strength of the hypothses which we express through a probability. We then want to update our belief of the hypotesis (posterior belief). In other words what is the probability of the choosen hypotesis given the data. We only have to compute one of the probabilities because $P(\\mu_1)= 1 - P(\\mu_0)$.\n",
    "\n",
    "The calculation is done sequentially. For each iteration we get a new data observation.A new row of genes.We continously update the posterior belief,for all genes,and put the posterior belief of each gene into a list. The belief get updated through calculating the marginal likelihood every time a new row is added and a product is taken between this marginal likelihood and all the presious marginal likelihood calculations bought for $P(  D|\\mu_1)$ and for$P(  D|\\mu_0)$ this is then put into the bayes formula $ P(\\mu | D) = \\frac{P_{\\mu} (D) \\cdot \\xi(\\mu)}{\\sum_{i=1} ^n P_{\\mu_i}(D) \\cdot \\xi(\\mu_i)} $.\n",
    "\n",
    "We want to find this probability for for each of the genes.This procedure is done for each gene.For each gene if the posterior probabilty is greater then some trechhold we add this gene to the list of important genes that are relvant for explaining that spesific symptom.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "The decision rule can be defined as\n",
    "\n",
    "$$ \\mu =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\mu_1 & P(\\mu_1|D) > s \\\\\n",
    "      \\mu_0 & else\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "where $s$ is a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3898c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a29b1e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'patch_sklearn' from 'sklearn' (/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/__init__.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xc/9tjchlhd1yn758nk26c1m1dc0000gn/T/ipykernel_18605/1535112038.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatch_sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpatch_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'patch_sklearn' from 'sklearn' (/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bec60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8be2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (['Covid-Recovered', 'Covid-Positive', 'No-Taste/Smell', 'Fever', 'Headache', 'Pneumonia', 'Stomach', 'Myocarditis', 'Blood-Clots', 'Death', \n",
    "        'Age', 'Gender', 'Income'] + \n",
    "         [f'Gene_{i+1:03}' for i in range(128)] + \n",
    "         ['Asthma', 'Obesity', 'Smoking', 'Diabetes', 'Heart disease', 'Hypertension',\n",
    "         'Vacc_1', 'Vacc_2', 'Vacc_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a0c4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = pd.read_csv(\"observation_features.csv\")\n",
    "treat_data = pd.read_csv(\"treatment_features.csv\") \n",
    "action_data = pd.read_csv(\"treatment_actions.csv\")\n",
    "outcome_data = pd.read_csv(\"treatment_outcomes.csv\") \n",
    "\n",
    "obs_data.columns = cols\n",
    "treat_data.columns = cols\n",
    "outcome_data.columns = cols[:10]\n",
    "action_data.columns = ['Treatment_1', 'Treatment_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "2c9f11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self, X, y, random_state=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def generate_binary_data(self, num_features, N, correlation=[0.9, 0.5]):\n",
    "        \"\"\"\n",
    "        From a number of features and one correlation vector,\n",
    "        create a data set with N observations and num_features,\n",
    "        with one target column that correlates with the features,\n",
    "        as given in the correlation vector\"\"\"\n",
    "        \n",
    "        data = np.random.choice(2, size=(N, num_features))\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"Target\"] = np.zeros(N).astype(int)\n",
    "        for i, cor in enumerate(correlation):\n",
    "            if i >= num_features:\n",
    "                break\n",
    "                \n",
    "            df[\"Target\"] |= df.iloc[:, i] * np.random.choice(2, size=N, p=[(1-cor), cor])\n",
    "            \n",
    "        return df.iloc[:, :num_features], df[\"Target\"]\n",
    "    \n",
    "    \n",
    "    def select_features(self, X, Y, threshold):\n",
    "        \"\"\" Select the most important features of a data set, where X (2D)\n",
    "        contains the feature data, and Y (1D) contains the target\n",
    "        \"\"\"\n",
    "        X, Y = np.array(X), np.array(Y)\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        n_data =  X.shape[0]\n",
    "        alpha_b = np.ones([n_features, 2 ])\n",
    "        beta_b = np.ones([n_features, 2])\n",
    "        log_p = np.zeros(n_features)\n",
    "\n",
    "        log_null = 0\n",
    "        alpha = 1\n",
    "        beta = 1  \n",
    "        for t in range(n_data):\n",
    "            p_null = alpha / (alpha + beta)\n",
    "            log_null += np.log(p_null)*Y[t] + np.log(1-p_null)*(1 - Y[t])\n",
    "            alpha += Y[t]\n",
    "            beta += (1 - Y[t])\n",
    "            for i in range(n_features):\n",
    "\n",
    "                    x_ti = int(X[t,i])\n",
    "                    p = alpha_b[i, x_ti] / (alpha_b[i, x_ti] + beta_b[i, x_ti])\n",
    "                    log_p[i] += np.log(p)*Y[t] + np.log(1-p)*(1 - Y[t])\n",
    "                    alpha_b[i, x_ti] += Y[t]\n",
    "                    beta_b[i, x_ti] += (1 - Y[t])\n",
    "        log_max=np.mean(log_p)\n",
    "        log_max2=np.mean(log_null)\n",
    "        log_p=log_p-log_max\n",
    "        log_null=log_null-log_max2\n",
    "        #p = np.exp(log_p) / (np.exp(log_p) + np.exp(log_null))\n",
    "        p = 1 / (np.exp(log_null - log_p) + 1)\n",
    "        #print(f\"{(log_p)=}\\n{(log_null)=}\\n{(log_p) + (log_null)=}\\n {p=}\")\n",
    "        #print(f\"{np.exp(log_p)=}\\n{np.exp(log_null)=}\\n{np.exp(log_p) + np.exp(log_null)=}\")\n",
    "\n",
    "        features = [i for i in range(n_features) if p[i] > threshold]\n",
    "\n",
    "        return features\n",
    "    \n",
    "        \n",
    "    def tune_parameters(self, X, y, clf, parameter_grid, scoring=None, cv=None):\n",
    "        \"\"\" Given X, y, a classifier and a parameter grid, \n",
    "        find the best parameters for the classifier and data using GridSearch\n",
    "        with cross validation.\n",
    "        \"\"\"\n",
    "        # The code below is from\n",
    "        # https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=self.random_state)\n",
    "\n",
    "        print(f\"# Tuning hyper-parameters for {scoring=}\")\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(     clf, \n",
    "                                parameter_grid, \n",
    "                                scoring=scoring,\n",
    "                                n_jobs=-1,\n",
    "                                cv=cv\n",
    "                            ).fit(X_train, y_train)\n",
    "\n",
    "        #piped_clf\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(f\"{clf.best_params_}, score: {clf.best_score_:.4f}\")\n",
    "        print()\n",
    "        \"\"\"print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\"\"\"\n",
    "\n",
    "        print(\"Classification report:\")\n",
    "        print()\n",
    "\n",
    "        print(classification_report(y_test, clf.predict(X_test)))\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    def find_alpha(self, beta,p):\n",
    "        \"\"\" Given beta and a mean probability p, compute and return the alpha of a beta distribution. \"\"\"\n",
    "        return beta*p/(1-p)\n",
    "\n",
    "    def find_efficacy(self, group_pos: pd.DataFrame, group_neg: pd.DataFrame, symptom, prior_probs):\n",
    "        if isinstance(symptom, int):\n",
    "            symptom_index = symptom\n",
    "            symptom_name = group_pos.keys()[symptom]\n",
    "        else:\n",
    "            symptom_name = symptom\n",
    "            symptom_index = list(group_pos.keys()).index(symptom)\n",
    "        \n",
    "        group_pos_count = np.sum(group_pos[symptom_name] * group_pos.iloc[:,1])\n",
    "        group_neg_count = np.sum(group_neg[symptom_name] * group_neg.iloc[:,1])\n",
    "\n",
    "        v = group_pos_count/len(group_pos)\n",
    "        n_v = group_neg_count/len(group_neg)\n",
    "\n",
    "        if n_v == 0:\n",
    "            print(f'{v=}, {n_v=}: Division by zero')\n",
    "            return\n",
    "\n",
    "        IRR = v/n_v\n",
    "\n",
    "        #print(v, n_v)\n",
    "        efficacy = 100*(1- IRR)\n",
    "\n",
    "        N = 100_000\n",
    "        beta = 1\n",
    "        p = prior_probs[symptom_index]\n",
    "        alpha = self.find_alpha(beta,p)\n",
    "\n",
    "        samples_group_pos = stats.beta.rvs(alpha + group_pos_count, beta + len(group_pos) - group_pos_count, size=N)\n",
    "        samples_group_neg = stats.beta.rvs(alpha + group_neg_count, beta + len(group_neg) - group_neg_count, size=N)\n",
    "\n",
    "        samples_ve = 100 * (1 - samples_group_pos/samples_group_neg)\n",
    "        lower = np.percentile(samples_ve, 2.5)\n",
    "        upper = np.percentile(samples_ve, 97.5)\n",
    "        print(f'{symptom_name:15s}: {efficacy:3.3f} - ({lower:3.3f}, {upper:3.3f})')  \n",
    "        \n",
    "        \n",
    "    def side_effects(self, vacced_neg, un_vacced_neg, start, end):\n",
    "        df = pd.DataFrame(index=vacced_neg.keys()[start:end], \n",
    "                          columns = (\"p1 (%)\", \"p2 (%)\", \"Diff (%)\", \"Credible Interval (%)\", \"Null Hypothesis\", ),\n",
    "                         )\n",
    "        \n",
    "        for i in range(start, end):\n",
    "            symptom = vacced_neg.keys()[i]\n",
    "            p1 = vacced_neg.sum()[i] / len(self.y) / (len(vacced_neg) / len(self.y))\n",
    "            p2 = un_vacced_neg.sum()[i] / len(self.y) / (len(un_vacced_neg) / len(self.y))\n",
    "            \n",
    "            \n",
    "            \n",
    "            lower = (p1-p2 - 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "            higher = (p1-p2 + 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "            \n",
    "            p1, p2, lower, higher = p1 * 100, p2 * 100, lower * 100, higher * 100\n",
    "            \n",
    "            df.loc[symptom] = [round(p1, 4), round(p2, 4), round(p1 - p2, 4), (round(lower, 4), round(higher, 4)),\n",
    "                               \"rejected\" if lower>0 else \"not rejected\", ]\n",
    "            \n",
    "            \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def treatment_efficacy(self, outcome_treated, precondition_treated, outcome_untreated, precondition_untreated, p, symptom_name):\n",
    "        group_pos_count = np.sum(outcome_treated[symptom_name])\n",
    "        group_neg_count = np.sum(outcome_untreated[symptom_name])\n",
    "\n",
    "        group_pos_total = np.sum(precondition_treated[symptom_name])\n",
    "        group_neg_total = np.sum(precondition_untreated[symptom_name])\n",
    "\n",
    "        if any(v == 0 for v in (group_pos_total, group_neg_total, group_neg_count)):\n",
    "            print(f'{symptom_name:15s}: Division by zero - not enough data to compute efficacy' )\n",
    "            return\n",
    "\n",
    "        v = group_pos_count / group_pos_total\n",
    "        n_v = group_neg_count / group_neg_total\n",
    "\n",
    "        #print(f\"{group_pos_count=}, {group_pos_total=}\\n{group_neg_count=} {group_neg_total=}\\n,{v=}, {n_v=}\")\n",
    "\n",
    "        IRR = v/n_v\n",
    "\n",
    "        efficacy = 100 * (1- IRR)\n",
    "\n",
    "        N = 100_000\n",
    "        beta = 1\n",
    "        p\n",
    "        alpha = self.find_alpha(beta,p)\n",
    "\n",
    "        #symptom_name = symptom_names[symptom_index]\n",
    "\n",
    "        samples_group_pos = stats.beta.rvs(alpha + group_pos_count, beta + len(outcome_treated) - group_pos_count, size=N)\n",
    "        samples_group_neg = stats.beta.rvs(alpha + group_neg_count, beta + len(outcome_untreated) - group_neg_count, size=N)\n",
    "\n",
    "        samples_ve = 100 * (1 - samples_group_pos/samples_group_neg)\n",
    "        lower = np.percentile(samples_ve, 2.5)\n",
    "        upper = np.percentile(samples_ve, 97.5)\n",
    "        print(f'{symptom_name:15s}: {efficacy:7.3f} - 95% CI: ({lower:3.3f}, {upper:3.3f})')    \n",
    "        \n",
    "        return efficacy, (lower, upper)\n",
    "\n",
    "    def bootstrap(self, X=None, y=None, N=None):\n",
    "        if X is None:\n",
    "            X = self.X\n",
    "        if y is None:\n",
    "            y = self.y\n",
    "            \n",
    "        return resample(X, y, n_samples=N)\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "a7097003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1 (%)</th>\n",
       "      <th>p2 (%)</th>\n",
       "      <th>Diff (%)</th>\n",
       "      <th>Credible Interval (%)</th>\n",
       "      <th>Null Hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No-Taste/Smell</th>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>(-0.0067, 0.0554)</td>\n",
       "      <td>not rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fever</th>\n",
       "      <td>9.9028</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>9.3947</td>\n",
       "      <td>(9.1613, 9.6281)</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headache</th>\n",
       "      <td>5.5788</td>\n",
       "      <td>1.053</td>\n",
       "      <td>4.5258</td>\n",
       "      <td>(4.3287, 4.7229)</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>0.1332</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>-0.0106</td>\n",
       "      <td>(-0.0557, 0.0345)</td>\n",
       "      <td>not rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stomach</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.2574</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>(-0.0864, 0.0336)</td>\n",
       "      <td>not rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Myocarditis</th>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>(0.1273, 0.2077)</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blood-Clots</th>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>(0.0847, 0.1816)</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Death</th>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>(0.0213, 0.0494)</td>\n",
       "      <td>rejected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                p1 (%)  p2 (%) Diff (%) Credible Interval (%) Null Hypothesis\n",
       "No-Taste/Smell  0.0812  0.0568   0.0243     (-0.0067, 0.0554)    not rejected\n",
       "Fever           9.9028  0.5081   9.3947      (9.1613, 9.6281)        rejected\n",
       "Headache        5.5788   1.053   4.5258      (4.3287, 4.7229)        rejected\n",
       "Pneumonia       0.1332  0.1437  -0.0106     (-0.0557, 0.0345)    not rejected\n",
       "Stomach          0.231  0.2574  -0.0264     (-0.0864, 0.0336)    not rejected\n",
       "Myocarditis     0.2143  0.0468   0.1675      (0.1273, 0.2077)        rejected\n",
       "Blood-Clots     0.2435  0.1103   0.1331      (0.0847, 0.1816)        rejected\n",
       "Death           0.0354     0.0   0.0354      (0.0213, 0.0494)        rejected"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(un_vacced_pos.iloc[:,13:147], un_vacced_pos['Blood-Clots'], random_state=42)\n",
    "pipe.side_effects(vacced_neg, un_vacced_neg, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e61c7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_example(pipeline, X=None, y=None, synthetic=True):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    parameter_grid = [{'kernel': ['poly', 'rbf'],\n",
    "                         'C': [0.01, 0.1,1, 10, 100,],\n",
    "                         'gamma': [.1, .01, 1e-3]}, ]\n",
    "    \n",
    "    if X and y:\n",
    "        pass\n",
    "    \n",
    "    # The generate binary data function gives some correlation by default to 1st and 2nd feature\n",
    "    elif synthetic is True:\n",
    "        X, y = pipe.generate_binary_data(100, 1000)\n",
    "    else:\n",
    "        X, y = pipe.X, pipe.y\n",
    "        \n",
    "    best_features = pipe.select_features(X, y, 0.8)\n",
    "    print(f\"{best_features=}\")\n",
    "    \n",
    "    keys = list(X.keys())\n",
    "    for f in best_features:\n",
    "        print(keys[f], end=' ')\n",
    "    print()\n",
    "    \n",
    "    print(\"Classification using best features\")\n",
    "    pipeline.tune_parameters(X.iloc[:, best_features], y, SVC(), parameter_grid=parameter_grid)\n",
    "\n",
    "    \n",
    "    print(\"Classification using all features\")    \n",
    "    pipeline.tune_parameters(X, y, SVC(), parameter_grid=parameter_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f805b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_features=[2, 15, 36, 72, 81, 91, 95, 103]\n",
      "Gene_003 Gene_016 Gene_037 Gene_073 Gene_082 Gene_092 Gene_096 Gene_104 \n",
      "Classification using best features\n",
      "# Tuning hyper-parameters for scoring=None\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}, score: 0.9495\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      2404\n",
      "         1.0       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.95      2531\n",
      "   macro avg       0.47      0.50      0.49      2531\n",
      "weighted avg       0.90      0.95      0.93      2531\n",
      "\n",
      "\n",
      "Classification using all features\n",
      "# Tuning hyper-parameters for scoring=None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01, 'gamma': 0.1, 'kernel': 'poly'}, score: 0.9495\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      2404\n",
      "         1.0       0.00      0.00      0.00       127\n",
      "\n",
      "    accuracy                           0.95      2531\n",
      "   macro avg       0.47      0.50      0.49      2531\n",
      "weighted avg       0.90      0.95      0.93      2531\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tellef\\Anaconda3\\envs\\in4080_2021\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "select_features_example(pipe, synthetic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af679235",
   "metadata": {},
   "source": [
    "The results above show that using only the 2 features that the select_features function returned, gives the same or better results than using all 100 features of the synthetic dataset, when there is a high correlation between the target and those two features, and the other features are completely random.\n",
    "\n",
    "Because the given data is unbalanced, it is hard to see how the classifier using only the selected features works compared to one using all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "26dbf419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_efficacy_example(pipeline, N=10000, p=1):\n",
    "    \"\"\" Create example data where the treatment is  about p effective, default 1,\n",
    "    to test the treatment_efficacy function\"\"\"\n",
    "    \n",
    "    X, y = pipeline.generate_binary_data(2, N, correlation =[0, 0.1])\n",
    "    X.columns = [0, 'Target']\n",
    "    \n",
    "    # Need to set y 'manually' here\n",
    "    y = (np.random.choice(2, size=N, p=(1-p, p)) * X[0] ^ 1) * X.Target * np.random.choice(2, size=N, p=(1-p, p))\n",
    "    y = pd.DataFrame(y, columns=['Target'])\n",
    "    \n",
    "    prior_prob = np.sum(X.Target) / len(y)\n",
    "    \n",
    "        # Partition X and y into the groups where treatment is given or not given, and test efficacy\n",
    "    pipeline.treatment_efficacy(y[X[0] == 1], X[X[0] == 1], y[X[0] == 0], X[X[0] == 0], prior_prob, 'Target')\n",
    "    \n",
    "    return X.assign(y=y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "9a6ec098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaccine_efficacy_example(pipeline, N=10000, p=0.9):\n",
    "    \"\"\" Here p is the chance that a vaccinated person does not get symptom\n",
    "    and that a non-vaccinated person does get the symptom.\n",
    "    p = 0.5 would mean no effect, as both groups would be equally susceptible\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = pipeline.generate_binary_data(1, N, correlation =[1-p])\n",
    "    \n",
    "    # Need to set y 'manually' here as well, \n",
    "    # here by 'flipping' a random amount of vaccination bits\n",
    "    y = (np.random.choice(2, size=N, p=(1-p, p)) ^ X[0])\n",
    "    X = X.assign(Target=y)\n",
    "    \n",
    "    prior_probs = [0, np.sum(X.Target) / len(y)]\n",
    "    \n",
    "    # Partition X and y into vaccinated and non-vaccinated groups\n",
    "    pipeline.find_efficacy(X[X[0] == 1], X[X[0] == 0], 'Target', prior_probs)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "02c2c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target         :  88.854 - 95% CI: (87.389, 90.188)\n"
     ]
    }
   ],
   "source": [
    "t = treatment_efficacy_example(pipe, p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "84eacf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target         : 30.825 - (27.986, 33.536)\n"
     ]
    }
   ],
   "source": [
    "X = vaccine_efficacy_example(pipe, p=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "30554e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = np.array(obs_data.iloc[:,0:10])\n",
    "age = obs_data.iloc[:,10]\n",
    "gender = obs_data.iloc[:,11]\n",
    "income = obs_data.iloc[:,12]\n",
    "genome = obs_data.iloc[:,13:141]\n",
    "comorbidities = obs_data.iloc[:,141:147]\n",
    "vaccination_status = np.array(obs_data.iloc[:,147:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bfcd88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_0 = select_features(np.array(un_vacced_pos.iloc[:,13:147]),np.array(un_vacced_pos['No-Taste/Smell']), 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17b9b0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 53, 60, 76, 85, 96, 120]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf92a54",
   "metadata": {},
   "source": [
    "## 1b) Estimating the efficacy of vaccines\n",
    "\n",
    "We estimate the efficacy of the vaccines by\n",
    "$$ 100 \\cdot (1-IRR)$$\n",
    "where IRR is the ratio of the vaccinated incidence rate and not vaccinated incidence incidenes ([link](https://www.nejm.org/doi/full/10.1056/NEJMoa2034577)). This means that the relationship we model for each symptom is as given below:\n",
    "\n",
    "$r_v = P(symptom = 1 | vaccine = 1)$ and\n",
    "\n",
    "$r_n = P(symptom = 1 | vaccine = 0)$\n",
    "\n",
    "to obtain $IRR = 100 * [1 - r_v / r_n]$\n",
    "\n",
    "We obtain a Bayesian estimate of $r_v, r_n$\n",
    "through the Beta-Bernoulli conjugate prior.\n",
    "\n",
    "As in the abovementioned article, we use a Bayesian Beta-Binomial model. Hence, our prior belief is assumed to have a Beta distribution and the Likelihood of observed data is Binomial distributed. This results in a Beta-distributed posterior (more details will follow afterwards).\n",
    "\n",
    "We set a low beta value for the prior distribution because we are uncertain about the actual distribution and compute a mean prior probability of each symptom from the data. Given the beta value of 1 and the mean probability, we compute the alpha value using the function alpha = beta \\* p/(1-p), which for p in (0, 0.5] returns an alpha in (0, 1]. If p is 0.5 this would make the beta distribution uniform, with alpha = beta = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6c9e3d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficacy of the vaccinated:\n",
      "Covid-Recovered: 28.965 - (20.116, 36.812)\n",
      "Covid-Positive : 21.464 - (19.611, 23.273)\n",
      "No-Taste/Smell : 47.521 - (41.631, 52.855)\n",
      "Fever          : 51.575 - (44.926, 57.473)\n",
      "Headache       : 45.473 - (29.024, 58.324)\n",
      "Pneumonia      : 57.810 - (51.553, 63.345)\n",
      "Stomach        : 50.542 - (25.878, 67.375)\n",
      "Myocarditis    : 44.531 - (28.495, 57.066)\n",
      "Blood-Clots    : 57.190 - (50.870, 62.739)\n",
      "Death          : 93.394 - (90.539, 95.673)\n"
     ]
    }
   ],
   "source": [
    "#samples with vaccinations or not:\n",
    "vacced = obs_data[np.sum(obs_data.iloc[:,-3:], axis=1) == 1]\n",
    "vacced_neg = vacced[vacced.iloc[:,1]==0]\n",
    "vacced_pos = vacced[vacced.iloc[:,1]==1]\n",
    "\n",
    "un_vacced = obs_data[np.sum(obs_data.iloc[:,-3:], axis=1) == 0]\n",
    "un_vacced_neg = un_vacced[un_vacced.iloc[:,1]==0]\n",
    "un_vacced_pos = un_vacced[un_vacced.iloc[:,1]==1]\n",
    "\n",
    "symptom_names = ['Covid-Recovered', 'Covid-Positive', 'No-Taste/Smell', 'Fever', 'Headache', 'Pneumonia', 'Stomach', 'Myocarditis', 'Blood-Clots', 'Death']\n",
    "prior_probs= [np.sum(obs_data.iloc[:,i]) / len(obs_data) for i, key in enumerate(symptom_names)]\n",
    "\n",
    "print(\"Efficacy of the vaccinated:\")\n",
    "for i, s in enumerate(symptom_names):\n",
    "    pipe.find_efficacy(vacced,un_vacced,i,prior_probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "d81522ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 1\n",
      "Covid-Recovered: 19.633 - (6.144, 31.634)\n",
      "Covid-Positive : 11.296 - (8.525, 14.003)\n",
      "No-Taste/Smell : 34.419 - (24.517, 43.415)\n",
      "Fever          : 43.590 - (32.826, 53.031)\n",
      "Headache       : 30.767 - (2.559, 52.160)\n",
      "Pneumonia      : 54.129 - (44.208, 62.742)\n",
      "Stomach        : 28.704 - (-17.038, 59.457)\n",
      "Myocarditis    : 36.093 - (10.650, 55.837)\n",
      "Blood-Clots    : 48.746 - (38.180, 57.936)\n",
      "Death          : 95.704 - (91.577, 98.425)\n",
      "\n",
      "type 2\n",
      "Covid-Recovered: 28.837 - (16.353, 39.890)\n",
      "Covid-Positive : 20.584 - (17.961, 23.137)\n",
      "No-Taste/Smell : 43.109 - (34.077, 51.257)\n",
      "Fever          : 45.703 - (35.286, 54.943)\n",
      "Headache       : 39.907 - (14.047, 59.492)\n",
      "Pneumonia      : 48.345 - (37.729, 57.543)\n",
      "Stomach        : 70.324 - (42.749, 87.591)\n",
      "Myocarditis    : 35.284 - (9.930, 55.053)\n",
      "Blood-Clots    : 47.762 - (37.135, 57.070)\n",
      "Death          : 92.922 - (87.710, 96.627)\n",
      "\n",
      "type 3\n",
      "Covid-Recovered: 38.211 - (26.793, 48.235)\n",
      "Covid-Positive : 32.271 - (29.916, 34.586)\n",
      "No-Taste/Smell : 64.686 - (57.872, 70.779)\n",
      "Fever          : 65.183 - (57.075, 72.185)\n",
      "Headache       : 65.346 - (46.785, 79.147)\n",
      "Pneumonia      : 70.765 - (63.152, 77.316)\n",
      "Stomach        : 52.328 - (16.691, 75.603)\n",
      "Myocarditis    : 61.919 - (43.363, 75.983)\n",
      "Blood-Clots    : 74.762 - (67.770, 80.745)\n",
      "Death          : 91.603 - (86.006, 95.694)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vacc_type1 = obs_data[obs_data.Vacc_1 == 1]\n",
    "vacc_type2 = obs_data[obs_data.Vacc_2 == 1]\n",
    "vacc_type3 = obs_data[obs_data.Vacc_3 == 1]\n",
    "vaccination_types = [vacc_type1,vacc_type2,vacc_type3]\n",
    "vaccination_names = ['type 1', 'type 2', 'type 3']\n",
    "\n",
    "for name in vaccination_names:\n",
    "    print(name)\n",
    "    index = vaccination_names.index(name)\n",
    "    for i, s in enumerate(symptom_names):\n",
    "        pipe.find_efficacy(vaccination_types[index],un_vacced,i,prior_probs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8e5d6d",
   "metadata": {},
   "source": [
    "## 1c) Estimating the probability of vaccination side-effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed7484",
   "metadata": {},
   "source": [
    "Using the Bayes theorem, we will estimate the probability of vaccination side-effects. In other words, the probability of getting symptoms given that a person is vaccinated and has tested negative.\n",
    "$$p_1 = P(symptom | vaccine,covid') = \\frac{P(symptom \\cap vaccine,covid')}{P(vaccine,covid')} $$\n",
    "$$p_2 = P(symptom | vaccine',covid') = \\frac{P(symptom \\cap vaccine',covid')}{P(vaccine',covid')} $$\n",
    "\n",
    "We want to test the following hypothesis:\n",
    "$$ h_0: p_1 - p_2 \\leq 0 $$\n",
    "$$h_a: p_1 - p_2 > 0 $$\n",
    "\n",
    "We make a confidence intervall for each symptom, and reject the null hypothesis if confidence intervall does not include zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eae2f8",
   "metadata": {},
   "source": [
    "**A large-sample 95% confidence interval for $p_1 - p_2$**:\n",
    "\n",
    "In this task it seems appropiate to estimate confidence intervalls instead of doing the task of comparison through hypotesis testing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The variables X and Y  represents the number of individuals in each sample having a certain  characteristic that defines $p_1$ and $p2$.Provided the population sizes are much larger than the sample sizes, the distribution\n",
    "of X can be choosen to be binomial with parameters m and $p_1$, and similarly, Y is choosen\n",
    "to be a binomial variable with parameters n and $p_2$. The samples are assumed to be independent of each other.Therefore X and Y are independent rv’s.\n",
    "\n",
    "The estimator for $ p_1-p_2 $, the difference in population proportions, is\n",
    "the  difference in sample proportions $\\frac{X}{m} - \\frac{Y}{n}$ .  $ \\hat{p_1} = \\frac{X}{m}$ and\n",
    "$\\hat{p_2} = \\frac{Y}{m}$, the estimator of $ p_1-p_2 $ can be expressed as $\\hat{p_1} - \\hat{p_2}$.\n",
    "\n",
    "$E[\\hat{p_1} - \\hat{p_2}]=p_1-p_2$ so $\\hat{p_1} - \\hat{p_2}$ is an unbiased estimate of $p_1-p_2$ \n",
    "\n",
    "$\\hat{p_1}=\\frac{X}{m}$ and $\\hat{p_2}=\\frac{y}{n}$ are aproximately normal distributed when m and n are large.\n",
    "\n",
    "\n",
    "Refrence: Modern Mathematical Statistic with applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "466d3e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-Taste/Smell : (-0.00007,0.00055)\n",
      "Fever          : ( 0.09161,0.09628)\n",
      "Headache       : ( 0.04329,0.04723)\n",
      "Pneumonia      : (-0.00056,0.00035)\n",
      "Stomach        : (-0.00086,0.00034)\n",
      "Myocarditis    : ( 0.00127,0.00208)\n",
      "Blood-Clots    : ( 0.00085,0.00182)\n",
      "Death          : ( 0.00021,0.00049)\n"
     ]
    }
   ],
   "source": [
    "vac_probs = [(vacced_neg.sum()[i] / len(obs_data)) / (len(vacced_neg) / len(obs_data)) for i in range(2,10)]\n",
    "unvac_probs = [(un_vacced_neg.sum()[i] / len(obs_data)) / (len(un_vacced_neg) / len(obs_data)) for i in range(2,10)]\n",
    "list(zip(vac_probs, unvac_probs))\n",
    "np.array(vac_probs) - np.array(unvac_probs)\n",
    "\n",
    "i = 2\n",
    "for p1, p2 in zip(vac_probs, unvac_probs):\n",
    "    lower = (p1-p2 - 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "    higher = (p1-p2 + 1.64 * np.sqrt((p1*(1-p1) / len(vacced_neg)) + (p2 * (1-p2) / len(un_vacced_neg))))\n",
    "    print(f\"{symptom_names[i]:15s}: ({lower:8.5f},{higher:6.5f})\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "523a5fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covid-Recovered</th>\n",
       "      <th>Covid-Positive</th>\n",
       "      <th>No-Taste/Smell</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Stomach</th>\n",
       "      <th>Myocarditis</th>\n",
       "      <th>Blood-Clots</th>\n",
       "      <th>Death</th>\n",
       "      <th>...</th>\n",
       "      <th>Gene_128</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Heart disease</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Vacc_1</th>\n",
       "      <th>Vacc_2</th>\n",
       "      <th>Vacc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Covid-Recovered  Covid-Positive  No-Taste/Smell  Fever  Headache  \\\n",
       "0                0.0             1.0             0.0    0.0       0.0   \n",
       "1                0.0             1.0             0.0    0.0       0.0   \n",
       "2                0.0             1.0             1.0    0.0       0.0   \n",
       "3                0.0             1.0             0.0    0.0       0.0   \n",
       "4                0.0             1.0             0.0    0.0       0.0   \n",
       "..               ...             ...             ...    ...       ...   \n",
       "872              0.0             1.0             0.0    0.0       0.0   \n",
       "873              0.0             1.0             0.0    0.0       0.0   \n",
       "874              0.0             1.0             0.0    0.0       0.0   \n",
       "875              0.0             1.0             0.0    0.0       0.0   \n",
       "876              0.0             1.0             0.0    0.0       0.0   \n",
       "\n",
       "     Pneumonia  Stomach  Myocarditis  Blood-Clots  Death  ...  Gene_128  \\\n",
       "0          0.0      0.0          0.0          0.0    0.0  ...       0.0   \n",
       "1          0.0      0.0          0.0          0.0    0.0  ...       0.0   \n",
       "2          0.0      0.0          0.0          0.0    0.0  ...       0.0   \n",
       "3          0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "4          0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "..         ...      ...          ...          ...    ...  ...       ...   \n",
       "872        0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "873        0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "874        0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "875        0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "876        0.0      0.0          0.0          1.0    0.0  ...       0.0   \n",
       "\n",
       "     Asthma  Obesity  Smoking  Diabetes  Heart disease  Hypertension  Vacc_1  \\\n",
       "0       0.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "1       0.0      0.0      0.0       0.0            0.0           0.0     1.0   \n",
       "2       0.0      0.0      0.0       1.0            0.0           0.0     0.0   \n",
       "3       0.0      0.0      0.0       1.0            0.0           0.0     1.0   \n",
       "4       0.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "..      ...      ...      ...       ...            ...           ...     ...   \n",
       "872     0.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "873     0.0      0.0      0.0       0.0            0.0           0.0     1.0   \n",
       "874     0.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "875     0.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "876     0.0      0.0      0.0       0.0            0.0           0.0     1.0   \n",
       "\n",
       "     Vacc_2  Vacc_3  \n",
       "0       0.0     0.0  \n",
       "1       0.0     0.0  \n",
       "2       0.0     0.0  \n",
       "3       0.0     0.0  \n",
       "4       1.0     0.0  \n",
       "..      ...     ...  \n",
       "872     0.0     0.0  \n",
       "873     0.0     0.0  \n",
       "874     0.0     1.0  \n",
       "875     1.0     0.0  \n",
       "876     0.0     0.0  \n",
       "\n",
       "[877 rows x 150 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "173d700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Covid-Recovered     90.0\n",
       " Covid-Positive     877.0\n",
       " No-Taste/Smell      23.0\n",
       " Fever               18.0\n",
       " Headache             1.0\n",
       " Pneumonia           19.0\n",
       " Stomach              3.0\n",
       " Myocarditis          6.0\n",
       " Blood-Clots         17.0\n",
       " Death                8.0\n",
       " dtype: float64,\n",
       " Covid-Recovered     90.0\n",
       " Covid-Positive     877.0\n",
       " No-Taste/Smell      49.0\n",
       " Fever               24.0\n",
       " Headache             7.0\n",
       " Pneumonia           34.0\n",
       " Stomach              5.0\n",
       " Myocarditis         13.0\n",
       " Blood-Clots         34.0\n",
       " Death               10.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_data.sum(), treat_data.sum()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7ec4c045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Covid-Recovered</th>\n",
       "      <th>Covid-Positive</th>\n",
       "      <th>No-Taste/Smell</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Stomach</th>\n",
       "      <th>Myocarditis</th>\n",
       "      <th>Blood-Clots</th>\n",
       "      <th>Death</th>\n",
       "      <th>...</th>\n",
       "      <th>Gene_128</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Heart disease</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Vacc_1</th>\n",
       "      <th>Vacc_2</th>\n",
       "      <th>Vacc_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Covid-Recovered  Covid-Positive  No-Taste/Smell  Fever  Headache  \\\n",
       "2                0.0             1.0             1.0    0.0       0.0   \n",
       "10               0.0             1.0             0.0    0.0       0.0   \n",
       "15               0.0             1.0             0.0    0.0       0.0   \n",
       "16               0.0             1.0             1.0    0.0       0.0   \n",
       "19               0.0             1.0             0.0    0.0       0.0   \n",
       "..               ...             ...             ...    ...       ...   \n",
       "860              1.0             1.0             0.0    0.0       0.0   \n",
       "863              0.0             1.0             0.0    0.0       0.0   \n",
       "864              0.0             1.0             0.0    0.0       0.0   \n",
       "866              0.0             1.0             1.0    0.0       0.0   \n",
       "876              0.0             1.0             0.0    0.0       0.0   \n",
       "\n",
       "     Pneumonia  Stomach  Myocarditis  Blood-Clots  Death  ...  Gene_128  \\\n",
       "2          0.0      0.0          0.0          0.0    0.0  ...       0.0   \n",
       "10         0.0      0.0          0.0          0.0    1.0  ...       1.0   \n",
       "15         0.0      0.0          0.0          1.0    0.0  ...       1.0   \n",
       "16         0.0      0.0          0.0          0.0    0.0  ...       0.0   \n",
       "19         0.0      1.0          0.0          0.0    0.0  ...       1.0   \n",
       "..         ...      ...          ...          ...    ...  ...       ...   \n",
       "860        0.0      0.0          0.0          1.0    0.0  ...       1.0   \n",
       "863        1.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "864        0.0      0.0          0.0          1.0    0.0  ...       0.0   \n",
       "866        0.0      0.0          0.0          0.0    0.0  ...       1.0   \n",
       "876        0.0      0.0          0.0          1.0    0.0  ...       0.0   \n",
       "\n",
       "     Asthma  Obesity  Smoking  Diabetes  Heart disease  Hypertension  Vacc_1  \\\n",
       "2       0.0      0.0      0.0       1.0            0.0           0.0     0.0   \n",
       "10      1.0      0.0      0.0       0.0            0.0           0.0     0.0   \n",
       "15      0.0      1.0      0.0       0.0            0.0           0.0     0.0   \n",
       "16      0.0      0.0      1.0       0.0            0.0           1.0     0.0   \n",
       "19      0.0      0.0      1.0       0.0            0.0           0.0     0.0   \n",
       "..      ...      ...      ...       ...            ...           ...     ...   \n",
       "860     0.0      0.0      0.0       0.0            0.0           1.0     0.0   \n",
       "863     0.0      0.0      1.0       0.0            0.0           0.0     0.0   \n",
       "864     0.0      0.0      0.0       1.0            0.0           1.0     1.0   \n",
       "866     0.0      0.0      0.0       1.0            0.0           0.0     0.0   \n",
       "876     0.0      0.0      0.0       0.0            0.0           0.0     1.0   \n",
       "\n",
       "     Vacc_2  Vacc_3  \n",
       "2       0.0     0.0  \n",
       "10      0.0     0.0  \n",
       "15      0.0     0.0  \n",
       "16      0.0     0.0  \n",
       "19      0.0     0.0  \n",
       "..      ...     ...  \n",
       "860     0.0     1.0  \n",
       "863     0.0     0.0  \n",
       "864     0.0     0.0  \n",
       "866     0.0     0.0  \n",
       "876     0.0     0.0  \n",
       "\n",
       "[164 rows x 150 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_treat_data = treat_data.copy()[((np.sum(treat_data.iloc[:,2:10],axis=1) > 0.0) \n",
    "              | np.sum(outcome_data.iloc[:,2:10],axis=1) > 0.0)]\n",
    "new_treat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "084662ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4289214852.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  group_first = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4289214852.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  group_second = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4289214852.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  group_both = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4289214852.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  group_none = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]\n"
     ]
    }
   ],
   "source": [
    "group_first = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
    "group_second = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
    "group_both = new_treat_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
    "group_none = new_treat_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f497a18",
   "metadata": {},
   "source": [
    "The relation we are modelling is whether any of the individuals who had symptoms do not have those symptoms after treatment or got symptoms from the treatment. \n",
    "\n",
    "We are not interested in the outcomes for individuals who did not have any symptoms neither before nor after the treatment.\n",
    "\n",
    "We do this modelling task in a similar way that we did the modelling for vaccine efficacy. Since we now have data from before and after a treatment, we calculate the ratio of people who still have symptoms after treatment to the people who had symptoms before treatment for both the treated group and the control group. \n",
    "\n",
    "We estimate the efficacy of the treatments by\n",
    "$$ 100 \\cdot (1-IRR)$$\n",
    "where IRR is the ratio of the treated incidence rate and not treated incidence rate ([link](https://www.nejm.org/doi/full/10.1056/NEJMoa2034577)). This means that the relationship we model for each symptom is as given below:\n",
    "\n",
    "$t_1 = P(symptom = 1 | treatment = 1)$ after treatment, $t_0 = P(symptom = 1 | treatment = 1) $ before treatment.\n",
    "\n",
    "$n_1 = P(symptom = 1 | treatment = 0)$ after treatment, $n_0 = P(symptom = 1 | treatment = 0) $ before treatment\n",
    "\n",
    "$r_t = t_1 / t_0$ and\n",
    "\n",
    "$r_n = n_1 / n_0$\n",
    "\n",
    "to obtain $IRR = 100 * [1 - r_t / r_n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccac94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b4f665fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outcome_data = outcome_data.copy()[((np.sum(treat_data.iloc[:,2:10],axis=1) > 0.0) \n",
    "              | np.sum(outcome_data.iloc[:,2:10],axis=1) > 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e809ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4031450266.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  outcome_first = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4031450266.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  outcome_second = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4031450266.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  outcome_both = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
      "C:\\Users\\Tellef\\AppData\\Local\\Temp/ipykernel_4892/4031450266.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  outcome_none = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]\n"
     ]
    }
   ],
   "source": [
    "outcome_first = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 0))]\n",
    "outcome_second = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 1))]\n",
    "outcome_both = new_outcome_data[((action_data.iloc[:,0] == 1) & (action_data.iloc[:,1] == 1))]\n",
    "outcome_none = new_outcome_data[((action_data.iloc[:,0] == 0) & (action_data.iloc[:,1] == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c939ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treatment_efficacy(outcome_treated, precondition_treated, outcome_untreated, precondition_untreated, prior_probs, symptom_name):\n",
    "    group_pos_count = np.sum(outcome_treated[symptom_name])\n",
    "    group_neg_count = np.sum(outcome_untreated[symptom_name])\n",
    "    \n",
    "    group_pos_total = np.sum(precondition_treated[symptom_name])\n",
    "    group_neg_total = np.sum(precondition_untreated[symptom_name])\n",
    "    \n",
    "    if any(v == 0 for v in (group_pos_total, group_neg_total, group_neg_count)):\n",
    "        print(f'{symptom_name:15s}: Division by zero - not enough data to compute efficacy' )\n",
    "        return\n",
    "    \n",
    "    v = group_pos_count / group_pos_total\n",
    "    n_v = group_neg_count / group_neg_total\n",
    "\n",
    "    #print(f\"{group_pos_count=}, {group_pos_total=}\\n {group_neg_count=} {group_neg_total=}\\n, {v=}, {n_v=}\")\n",
    "\n",
    "    #IRR = \n",
    "    ratio = n_v/v\n",
    "\n",
    "    #efficacy = 100*(1- IRR)\n",
    "\n",
    "    N = len(precondition_treated) + len(precondition_untreated)\n",
    "    beta = 1\n",
    "    p = prior_probs[4]\n",
    "    alpha = find_alpha(beta,p)\n",
    "\n",
    "    #symptom_name = symptom_names[symptom_index]\n",
    "\n",
    "    samples_group_pos = stats.beta.rvs(alpha + group_pos_count, beta + len(outcome_treated) - group_pos_count, size=N)\n",
    "    samples_group_neg = stats.beta.rvs(alpha + group_neg_count, beta + len(outcome_untreated) - group_neg_count, size=N)\n",
    "\n",
    "    samples_ve = samples_group_neg/samples_group_pos\n",
    "    lower = np.percentile(samples_ve, 2.5)\n",
    "    upper = np.percentile(samples_ve, 97.5)\n",
    "    print(f'{symptom_name:15s}: {ratio:7.3f} - 95% CI: ({lower:3.3f}, {upper:3.3f})')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6ef8ce47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_treat_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4892/2003194193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprior_probs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_treat_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msym\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_outcome_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msym\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_treat_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymptom_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4892/2003194193.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprior_probs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_treat_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msym\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_outcome_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msym\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_treat_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymptom_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'new_treat_data' is not defined"
     ]
    }
   ],
   "source": [
    "prior_probs= [(np.sum(new_treat_data[sym]) + np.sum(new_outcome_data[sym])) / (len(new_treat_data) * 2) for sym in symptom_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "84ec8cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04908049080490805,\n",
       " 0.22028220282202823,\n",
       " 0.014080140801408014,\n",
       " 0.05853058530585306,\n",
       " 0.03214032140321403,\n",
       " 0.00936009360093601,\n",
       " 0.002820028200282003,\n",
       " 0.0035500355003550035,\n",
       " 0.00987009870098701,\n",
       " 0.003280032800328003]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "a643b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fever          :   1.667 - 95% CI: (0.428, 2.945)\n"
     ]
    }
   ],
   "source": [
    "treatment_efficacy(outcome_first, group_first, outcome_none, group_none, prior_probs, \"Fever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2a384535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fever          :  25.000 - 95% CI: (-36.003, 91.345)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25.0, (-36.0033976173197, 91.3452139050511))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.treatment_efficacy(outcome_second, group_second, outcome_none, group_none, prior_probs[4], \"Fever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e431606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Death          :  50.000 - 95% CI: (-351.382, 98.074)\n"
     ]
    }
   ],
   "source": [
    "treatment_efficacy(outcome_both, group_both, outcome_none, group_none, prior_probs, \"Death\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fe1712a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treatment 1 efficacy:\n",
      "No-Taste/Smell :  33.333 - 95% CI: (-17.816, 76.078)\n",
      "Fever          :  40.000 - 95% CI: (-113.846, 72.784)\n",
      "Headache       : 100.000 - 95% CI: (82.255, 100.000)\n",
      "Pneumonia      :  80.000 - 95% CI: (31.189, 97.368)\n",
      "Stomach        : Division by zero - not enough data to compute efficacy\n",
      "Myocarditis    :   0.000 - 95% CI: (-13566.425, 38.159)\n",
      "Blood-Clots    : 100.000 - 95% CI: (99.999, 100.000)\n",
      "Death          :   0.000 - 95% CI: (-1464.831, 62.276)\n",
      "\n",
      "treatment 2 efficacy:\n",
      "No-Taste/Smell :  71.429 - 95% CI: (53.353, 98.043)\n",
      "Fever          :  25.000 - 95% CI: (-38.861, 90.370)\n",
      "Headache       : 100.000 - 95% CI: (80.726, 100.000)\n",
      "Pneumonia      :   0.000 - 95% CI: (-106.610, 64.604)\n",
      "Stomach        :  33.333 - 95% CI: (-6637.086, 80.563)\n",
      "Myocarditis    :  75.000 - 95% CI: (-3528.948, 97.422)\n",
      "Blood-Clots    :  46.154 - 95% CI: (-62.011, 73.402)\n",
      "Death          :  50.000 - 95% CI: (-405.900, 98.695)\n",
      "\n",
      "both treatments efficacy:\n",
      "No-Taste/Smell : 100.000 - 95% CI: (95.266, 100.000)\n",
      "Fever          :  33.333 - 95% CI: (-10.235, 95.321)\n",
      "Headache       : 100.000 - 95% CI: (79.057, 100.000)\n",
      "Pneumonia      : 100.000 - 95% CI: (91.719, 100.000)\n",
      "Stomach        : 100.000 - 95% CI: (12.897, 100.000)\n",
      "Myocarditis    : 100.000 - 95% CI: (91.787, 100.000)\n",
      "Blood-Clots    : 100.000 - 95% CI: (99.999, 100.000)\n",
      "Death          :  50.000 - 95% CI: (-434.702, 98.650)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for outcome_treated, pre_treated, treatment in zip([outcome_first, outcome_second, outcome_both], \n",
    "                                        [group_first, group_second, group_both],\n",
    "                                                ['treatment 1', 'treatment 2', 'both treatments']):\n",
    "    print(f\"{treatment} efficacy:\")\n",
    "    for i, key in enumerate(outcome_data.keys()[2:]):\n",
    "        #print(key)\n",
    "        pipe.treatment_efficacy(outcome_treated, pre_treated, outcome_none, group_none, prior_probs[i], key)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}